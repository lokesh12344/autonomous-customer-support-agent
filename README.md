# ğŸ§  Next-Gen Autonomous Customer Support Agent

**Built with Agentic AI Â· LangChain ReAct Â· FastAPI Â· SQLite Â· ChromaDB Â· Local LLM Â· Stripe Test Mode**

A lightweight autonomous support agent capable of:

- Order lookups (SQLite)
- Refund execution (Stripe Test Mode)
- FAQ retrieval (Chroma vector search)
- Policy-aware reasoning & safety checks
- Real-time chat interface (Slack / Web UI)

---

## ğŸš€ Features

### Agentic ReAct Pipeline
Observe â†’ Reason â†’ Act â†’ Verify â†’ Reply

### Local LLM Inference
LLaMA/Mistral/Vicuna via Ollama

### Tool-Based Actions
- `order_tool` â†’ fetch order status
- `faq_tool` â†’ semantic FAQ retrieval
- `refund_tool` â†’ process refunds securely

### Safety & Guardrails
- Refund confirmation
- â‚¹10,000 refund limit
- DB verification before actions
- Auto human-escalation on low confidence

### Infrastructure
- FastAPI backend hosting the agent and endpoints
- ChromaDB for policy/FAQ embeddings & long-term memory
- SQLite for orders, customers, inventory, returns
- Slack/Web UI for live conversation demo

---

## ğŸ—ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| Backend | FastAPI (Python) |
| Agent Framework | LangChain (ReAct agent + tools) |
| Orchestration | Minimal LangGraph (optional) |
| LLM | Local LLaMA/Mistral via Ollama |
| Database | SQLite + SQLAlchemy |
| Vector Store | ChromaDB |
| Payments | Stripe API (Test Mode) |
| UI | Slack Bot / Streamlit Chat UI |

---

## ğŸ“‚ Project Structure

```
/project-root
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI server
â”‚   â”œâ”€â”€ agent.py             # LangChain ReAct agent
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ orders.py        # SQLite order lookup tool
â”‚   â”‚   â”œâ”€â”€ refund.py        # Stripe refund tool
â”‚   â”‚   â””â”€â”€ faq.py           # Chroma retrieval tool
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ models.py        # SQLAlchemy models
â”‚   â”‚   â””â”€â”€ seed.py          # Sample seed data
â”‚   â””â”€â”€ memory/
â”‚       â””â”€â”€ vectorstore.py   # Chroma embedding setup
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ slack_bot.py         # Slack event handler
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .env.example
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Start Ollama (Local LLM)

```bash
ollama pull llama3
ollama serve
```

### 3ï¸âƒ£ Configure Environment

Copy `.env.example` â†’ `.env` and fill:

```env
STRIPE_API_KEY=sk_test_****
LLM_MODEL=llama3
```

### 4ï¸âƒ£ Initialize SQLite & Chroma

```bash
python app/db/seed.py
```

### 5ï¸âƒ£ Run FastAPI Server

```bash
uvicorn app.main:app --reload
```

### 6ï¸âƒ£ (Optional) Run Slack Bot

```bash
python ui/slack_bot.py
```

---

## ğŸ§ª Example Queries

- "Where is my order #8912?"
- "Process refund â‚¹7000 for order 1234."
- "Show me your return policy."
- "My product was damaged, what can I do?"

---

## ğŸ” Safety & Guardrails

- **Refund limit**: â‚¹10,000
- **Mandatory user confirmation**
- **DB-verified order + payment mapping**
- **No hallucinated financial actions**
- **Escalates to human on uncertainty**

---

## ğŸ“ˆ Roadmap

- [ ] Multi-channel (WhatsApp API)
- [ ] Postgres migration for scale
- [ ] Production LLaMA 3 70B hosting
- [ ] Auto-email receipts
- [ ] Multi-turn memory optimization

---
